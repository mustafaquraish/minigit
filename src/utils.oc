//* Common functions that can be used by all the modules, for
//* interacting with the state of the git repository.
import std::fs
import std::panic
import std::hash::sha1::{ SHA1Hash }
import std::sv::{ SV }
import std::zlib
import std::buffer::{ Buffer }
import std::bufferio::{ BufferIO }
import std::libc::{ memcpy }
import std::vector::{ Vector }
import std::set::{ Set }
import std::map::{ Map }
import std::sort::{ sort }
import std::time

import @core::{
    ObjectType,
    Object,
    StringHash,
    Index,
    IndexEntry,
    CurrentStatus,
    TreeEntry,
    Commit,
    FileChange,
}


def copy_sv(sv: SV): str {
    let mem = std::new<char>(sv.len + 1)
    memcpy(mem, sv.data, sv.len)
    mem[sv.len] = '\0'
    return mem
}

[extern] def realpath(path: str, resolved: &str): str
let repo_base_path: SV

def canonicalize_path(path: str): str {
    let rp = realpath(path, null)
    let sv = SV::from_str(rp)
    if sv.starts_with_sv(repo_base_path) {
        sv.chop_by_sv(repo_base_path)
        if sv.starts_with_str("/") {
            sv.chop_left()
        }
    }
    return sv.data.copy()
}

def try_expand_hash(hash: str): StringHash {
    let sv = SV::from_str(hash)
    let prefix = sv.chop_left(2)

    if sv.len < 1 {
        panic(`[-] Please provide at least 3 characters of the hash`)
    }

    let dir_path = `.git/objects/{prefix}`
    defer std::free(dir_path)

    if not fs::directory_exists(dir_path) {
        panic(`[-] No objects found for hash: {hash}`)
    }

    let name: str = null
    for entry : fs::iterate_directory(dir_path) {
        if entry.name.starts_with(sv.data) {
            // FIXME: Does this check make sense? Does it just waste time if we don't expect it to be the case?
            if name? {
                panic(`[-] Ambiguous hash: {hash}, could be either {prefix}{name} or {prefix}{entry.name}`)
            }
            name = entry.name
        }
    }

    if not name? {
        panic(`[-] No objects found for hash: {hash}`)
    }

    let sh: StringHash
    memcpy(sh.data, prefix.data, 2)
    memcpy(sh.data + 2, name, 38)
    sh.data[40] = '\0'
    return sh
}

def get_index(path: str): Index {
    if not fs::file_exists(path) {
        panic(`[-] No index file found at {path}`)
    }

    let contents = fs::read_file(path)
    let io = BufferIO::make(&contents)

    let header = io.read_u32()
    if header != 0x44495243 {  // "DIRC"
        panic("[-] Invalid index file header")
    }

    let data = contents.data
    let version = io.read_u32()
    let num_entries = io.read_u32()
    let entries = Map<str, IndexEntry>::new(capacity: num_entries)

    for let i = 0; i < num_entries; i++ {
        let entry: IndexEntry
        entry.ctime_s = io.read_u32()       // 0-4
        entry.ctime_n = io.read_u32()       // 4-8
        entry.mtime_s = io.read_u32()       // 8-12
        entry.mtime_n = io.read_u32()       // 12-16
        entry.dev = io.read_u32()           // 16-20
        entry.ino = io.read_u32()           // 20-24
        entry.modif = io.read_u32()         // 24-28
        entry.uid = io.read_u32()           // 28-32
        entry.gid = io.read_u32()           // 32-36
        entry.size = io.read_u32()          // 36-40

        let hash_bytes: SHA1Hash
        io.read_bytes(hash_bytes.data, 20)  // 40-60
        entry.hash = StringHash::from_hash_bytes(&hash_bytes)

        entry.flags = io.read_u16()         // 60-62

        let buf = Buffer::make()
        while true {
            let c = io.read_i8()
            if c == 0 then break
            buf.putc(c as char)
        }
        entry.path = buf.str()

        let padding = 7 - ((62 + buf.size) % 8)
        if padding > 0 then io.read_bytes(null, padding)

        entries.insert(entry.path, entry)
    }

    return Index(version, entries)
}

def write_index(index: &Index, path: str = ".git/index") {
    let buf = Buffer::make()
    defer buf.free()
    let io = BufferIO::make(&buf)

    io.write_u32(0x44495243)  // "DIRC"
    io.write_u32(index.version)
    io.write_u32(index.entries.size)

    let entries = index.sorted_entries()
    defer entries.free()

    for entry : entries.iter() {
        io.write_u32(entry.ctime_s)
        io.write_u32(entry.ctime_n)
        io.write_u32(entry.mtime_s)
        io.write_u32(entry.mtime_n)
        io.write_u32(entry.dev)
        io.write_u32(entry.ino)
        io.write_u32(entry.modif)
        io.write_u32(entry.uid)
        io.write_u32(entry.gid)
        io.write_u32(entry.size)

        let hash_bytes = entry.hash.to_hash_bytes()
        io.write_bytes(hash_bytes.data, 20)

        io.write_u16(entry.flags)

        let path_len = entry.path.len()
        io.write_bytes(entry.path, path_len)
        io.write_u8(0)

        let padding = 7 - ((62 + path_len) % 8)
        for let i = 0; i < padding; i++ {
            io.write_u8(0)
        }
    }

    let digest = SHA1Hash::from(buf)

    let file = fs::File::open(path, "w")
    file.write(buf.data, buf.size)
    file.write(digest.data, 20)
    file.close()
}


def object_exists(hash_str: &StringHash): bool {
    let hash_sv = SV(hash_str.data, 40)
    let prefix = hash_sv.chop_left(2)

    let dir_path = `.git/objects/{prefix}`
    defer std::free(dir_path)

    if not fs::directory_exists(dir_path) {
        return false
    }

    let file_path = `{dir_path}/{hash_sv}`
    let exists = fs::file_exists(file_path)
    std::free(file_path)

    return exists
}

def get_object(hash_str: &StringHash): Object {
    let hash_sv = SV(hash_str.data, 40)
    let prefix = hash_sv.chop_left(2)

    let dir_path = `.git/objects/{prefix}`
    defer std::free(dir_path)

    if not fs::directory_exists(dir_path) {
        panic(`[-] Object {hash_str.data:s} not found (missing directory {dir_path})`)
    }

    let file_path = `{dir_path}/{hash_sv}`
    defer std::free(file_path)

    if not fs::file_exists(file_path) {
        panic(`[-] Object {hash_str.data:s} not found (missing file {file_path})`)
    }

    let contents = fs::read_file(file_path)
    defer contents.free()

    let decompressed = zlib::decompress(contents)
    defer decompressed.free()

    let sv = decompressed.sv()
    let kind = sv.chop_by_delim(' ')
    let size = sv.chop_u32()
    sv.chop_left() // skip null byte


    let obj: Object

    if kind.eq_str("blob") {
        obj.type = ObjectType::Blob
        obj.u.blob = Buffer::make()
        obj.u.blob.putsv(sv)

    } else if kind.eq_str("tree") {
        obj.type = ObjectType::Tree

        let entries = Vector<TreeEntry>::new()
        while not sv.is_empty() {
            let mode = sv.chop_by_delim(' ')
            let name = sv.chop_by_delim('\0')
            let hash_sv = sv.chop_left(20)

            let hash_bytes: SHA1Hash
            memcpy(hash_bytes.data, hash_sv.data, 20)

            let entry: TreeEntry
            entry.mode = std::libc::strtoul(mode.data, null, 8) as u32
            entry.name = copy_sv(name)
            entry.hash = StringHash::from_hash_bytes(&hash_bytes)

            entries.push(entry)
        }
        obj.u.tree = entries

    } else if kind.eq_str("commit") {
        obj.type = ObjectType::Commit

        let commit = std::new<Commit>()
        commit.parents = Vector<StringHash>::new()
        while not sv.is_empty() {
            let line = sv.chop_line()
            if line.is_empty() break

            let key = line.chop_by_delim(' ')

            if key.eq_str("tree") {
                if line.len != 40 then panic(f"[-] Invalid tree hash: {line}")
                memcpy(commit.tree.data, line.data, 40)

            } else if key.eq_str("parent") {
                let parent: StringHash
                memcpy(parent.data, line.data, 40)
                commit.parents.push(parent)

            } else if key.eq_str("author") {
                let author_end = line.find_str("> ")
                if author_end < 0 then panic(f"[-] Invalid author line: {line}")
                commit.author = copy_sv(line.chop_left(author_end as u32 + 1))
                line.chop_left() // skip space

                commit.author_time = line.chop_u64()
                commit.author_tz = copy_sv(line)

            } else if key.eq_str("committer") {
                let committer_end = line.find_str("> ")
                if committer_end < 0 then panic(f"[-] Invalid committer line: {line}")
                commit.committer = copy_sv(line.chop_left(committer_end as u32 + 1))
                line.chop_left() // skip space

                commit.commit_time = line.chop_u64()
                commit.commit_tz = copy_sv(line)

            } else {
                panic(f"[-] Unknown key: {key}")
            }
        }

        if sv.ends_with_str("\n") {
            sv.chop_right()
        }
        commit.message = copy_sv(sv)
        obj.u.commit = commit

    } else {
        panic(f"[-] Unknown object type: {kind.data}")
    }


    return obj
}

def get_object_from_hash_str(hash_str: &StringHash): Object => get_object(hash_str)

def get_object_from_hash(hash: &SHA1Hash): Object {
    let hash_str = StringHash::from_hash_bytes(hash)
    return get_object(&hash_str)
}

def create_blob_object_from_file(filename: str): Object {
    if not fs::file_exists(filename) {
        panic(`[-] File '{filename}' not found`)
    }

    let contents = fs::read_file(filename)

    let obj: Object
    obj.type = ObjectType::Blob
    obj.u.blob = contents
    return obj
}

def serialize_object_from_body(type: ObjectType, body: Buffer): Buffer {
    let obj_data = Buffer::make()
    obj_data.putsf(`{type.str()} {body.size}`)
    obj_data.putc('\0')
    obj_data.putb(&body)
    return obj_data
}

def get_object_hash_only(obj: &Object): StringHash {
    let body = obj.create_bytes()
    defer body.free()

    let data = serialize_object_from_body(obj.type, body)
    defer data.free()

    let hash = SHA1Hash::from(data)
    let hash_str = StringHash::from_hash_bytes(&hash)
    return hash_str
}

def write_object_from_body(type: ObjectType, body: Buffer): StringHash {
    let data = serialize_object_from_body(type, body)
    defer data.free()

    let hash = SHA1Hash::from(data)
    let hash_str = StringHash::from_hash_bytes(&hash)
    let hash_sv = SV(hash_str.data, 40)

    let prefix = hash_sv.chop_left(2)

    let dir_path = `.git/objects/{prefix}`
    defer std::free(dir_path)

    fs::create_directory(dir_path, exists_ok: true)

    let file_path = `{dir_path}/{hash_sv}`
    defer std::free(file_path)

    let compressed = zlib::compress(data)
    defer compressed.free()

    fs::write_file(file_path, compressed)

    return hash_str
}

def write_object(obj: &Object): StringHash {
    let body = obj.create_bytes()
    defer body.free()

    return write_object_from_body(obj.type, body)
}


def create_tree_object_from_dir(dir_path: str, dry_run: bool = true): Object {
    let entries = Vector<TreeEntry>::new()
    defer entries.free()

    for entry : fs::iterate_directory(dir_path) {
        if entry.name.eq(".git") then continue

        let new_path = `{dir_path}/{entry.name}`
        defer std::free(new_path)

        let obj = match entry.type {
            Directory => create_tree_object_from_dir(new_path)
            File => create_blob_object_from_file(new_path)
            else => panic(`[-] Unknown file type: {entry.type}`)
        }
        let mode = match entry.type {
            Directory => 16384,  // 040000
            File => 33188,       // 0100644
            else => panic(`[-] Unknown file type: {entry.type}`)
        }
        let hash = write_object(&obj)

        entries.push(TreeEntry(
            name: entry.name,
            mode: mode,
            hash: hash
        ))
    }

    sort<TreeEntry>(entries.data, entries.size)

    let obj: Object
    obj.type = ObjectType::Tree
    obj.u.tree = entries
    return obj
}


def create_commit_object(tree_hash: &StringHash, parent_hashes: &Vector<StringHash>, message: str): Object {
    // FIXME: Need to get the actual author and committer from the environment
    let user = "Unknown User <unknown@example.com>"
    let timezone = Buffer::make(capacity: 6)
    defer timezone.free()

    let t = time::time(null)
    let timeinfo = time::localtime(&t)
    timezone.size += time::strftime(timezone.data as str, 6, "%z", timeinfo)

    let parent_hashes_copy = Vector<StringHash>::new()
    for parent : parent_hashes.iter() {
        parent_hashes_copy.push(parent)
    }

    let obj: Object
    obj.type = ObjectType::Commit

    obj.u.commit = std::new<Commit>()
    *obj.u.commit = Commit(
        tree: *tree_hash,
        parents: parent_hashes_copy,
        author: user.copy(),
        author_time: t as u64,
        author_tz: timezone.new_str(),
        committer: user.copy(),
        commit_time: t as u64,
        commit_tz: timezone.new_str(),
        message: message.copy(),
    )
    return obj
}

def restore_working_directory_from_tree(tree_hash: &StringHash, path: str = ".") {
    let obj = get_object_from_hash_str(tree_hash)
    defer obj.free()

    if obj.type != ObjectType::Tree {
        panic(`[-] Object {tree_hash.data} is not a tree`)
    }

    fs::create_directory(path, exists_ok: true)

    for entry : obj.u.tree.iter() {
        let new_path = `{path}/{entry.name}`

        if entry.mode == 16384 { // Directory
            restore_working_directory_from_tree(&entry.hash, new_path)

        } else {
            // println(`[+] Restoring {new_path}`)
            let blob = get_object_from_hash_str(&entry.hash)
            defer blob.free()
            assert blob.type == ObjectType::Blob, "Object is not a blob"

            fs::write_file(new_path, blob.u.blob)
            // if entry.mode == 33261 {
            //     fs::chmod(new_path, 0o755)
            // }
        }
    }
}

def get_head_commit_hash(): StringHash {
    let head_contents = fs::read_file(".git/HEAD")
    defer head_contents.free()

    let head_sv = head_contents.sv()
    if not head_sv.starts_with_str("ref: ") {
        panic(`[-] Unknown HEAD file contents: '{head_sv}'`)
    }
    head_sv.chop_by_delim(' ')

    let ref_path = `.git/{head_sv}`
    defer std::free(ref_path)

    let ref_len = ref_path.len()
    if ref_path[ref_len - 1] == '\n' then ref_path[ref_len - 1] = '\0'

    let ref_contents = fs::read_file(ref_path)
    let hash = StringHash::from_string(ref_contents.str())
    defer ref_contents.free()

    return hash
}

def collect_files_working_directory(dir_path: str, out: &Set<str>) {
    for entry : fs::iterate_directory(dir_path) {
        if entry.name.eq(".git") then continue

        let new_path = match dir_path {
            "." => entry.name.copy()
            else => `{dir_path}/{entry.name}`
        }
        defer std::free(new_path)

        match entry.type {
            Directory => collect_files_working_directory(new_path, out)
            File => out.add(canonicalize_path(new_path))
            else => panic(`[-] Unknown file type: {entry.type}`)
        }
    }
}

def collect_files_from_tree(tree_hash: &StringHash, out: &Map<str, StringHash>, dir_path: str) {
    let obj = get_object_from_hash_str(tree_hash)
    defer obj.free()

    if obj.type != ObjectType::Tree {
        panic(`[-] Object {tree_hash.data} is not a tree`)
    }

    for entry : obj.u.tree.iter() {
        if entry.name.eq(".git") then continue

        let new_path = match dir_path {
            "." => entry.name.copy()
            else => `{dir_path}/{entry.name}`
        }
        defer std::free(new_path)

        // FIXME: Change mode to `EntryType` enum
        match entry.mode {
            16384 => collect_files_from_tree(&entry.hash, out, new_path)
            33188 | 33261 => {
                let canon = new_path.copy()
                out.insert(canon, entry.hash)
            }
            else => panic(`[-] Unknown mode: {entry.mode}`)
        }
    }
}

// Get the list of added/modified/deleted files that are not staged
// (i.e. not in the index). We compare the index with the working
// directory to get this information.
def get_repository_status_unstaged(): CurrentStatus {
    let index = get_index(".git/index")
    defer index.free()

    // Files from the working directory
    let working_files_set = Set<str>::new()
    defer working_files_set.free()
    collect_files_working_directory(".", working_files_set)

    // Files from the HEAD commit's tree
    let tree_files_map = Map<str, StringHash>::new()
    defer tree_files_map.free()
    let commit_hash = get_head_commit_hash()
    let commit_obj = get_object_from_hash_str(&commit_hash)
    assert commit_obj.type == ObjectType::Commit, "HEAD is not a commit object"
    let tree_hash = commit_obj.u.commit.tree
    collect_files_from_tree(&tree_hash, tree_files_map, ".")

    // Changes we want to collect
    let staged_changes = Vector<FileChange>::new()
    let unstaged_changes = Vector<FileChange>::new()
    let untracked_changes = Vector<FileChange>::new()

    for entry : index.entries.iter_values() {
        let path = entry.path

        if working_files_set.contains(path) {
            let obj = create_blob_object_from_file(path)
            defer obj.free()

            let obj_hash = get_object_hash_only(&obj)
            if not obj_hash.eq(entry.hash) {
                unstaged_changes.push(FileChange(Modified, path.copy()))
            }

        } else {
            unstaged_changes.push(FileChange(Deleted, path.copy()))
        }

        let it = tree_files_map.get_item(path)
        if it? {
            if not it.value.eq(entry.hash) {
                staged_changes.push(FileChange(Modified, path.copy()))
            }
        } else {
            staged_changes.push(FileChange(Added, path.copy()))
        }
    }

    for path : working_files_set.iter() {
        if not index.entries.contains(path) {
            untracked_changes.push(FileChange(Added, path.copy()))
        }
        path.free()
    }
    for it : tree_files_map.iter() {
        let path = it.key
        if not index.entries.contains(path) {
            staged_changes.push(FileChange(Deleted, path.copy()))
        }
        path.free()
    }

    sort<FileChange>(staged_changes.data, staged_changes.size)
    sort<FileChange>(unstaged_changes.data, unstaged_changes.size)
    sort<FileChange>(untracked_changes.data, untracked_changes.size)

    return CurrentStatus(
        head_commit_hash: commit_hash,
        staged_changes: staged_changes,
        unstaged_changes: unstaged_changes,
        untracked_changes: untracked_changes
    )
}